{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-Nearest Neighbors\n",
    "\n",
    "The model for kNN is the entire training dataset. When a prediction is required for a unseen data instance, the kNN algorithm will search through the training dataset for the k-most similar instances. The prediction attribute of the most similar instances is summarized and returned as the prediction for the unseen instance.\n",
    "\n",
    "The similarity measure is dependent on the type of data. For real-valued data, the Euclidean distance can be used. Other other types of data such as categorical or binary data, Hamming distance can be used.\n",
    "\n",
    "In the case of regression problems, the average of the predicted attribute may be returned. In the case of classification, the most prevalent class may be returned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 - Explore the Data\n",
    "\n",
    "The test problem we will be using is iris classification. The problem is comprised of 150 observations of iris flowers from three different species. There are 4 measurements of given flowers: sepal length, sepal width, petal length and petal width, all in the same unit of centimeters. The predicted attribute is the species, which is one of setosa, versicolor or virginica.\n",
    "\n",
    "It is a standard dataset where the species is known for all instances. As such we can split the data into training and test datasets and use the results to evaluate our algorithm implementation. Good classification accuracy on this problem is above 90% correct, typically 96% or better.\n",
    "\n",
    "You can download the dataset for free from [iris.data](https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data), see the resources section for further details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "import itertools\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "iris= pd.read_csv('iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_length  sepal_width  petal_length  petal_width species\n",
      "0           5.1          3.5           1.4          0.2  setosa\n",
      "1           4.9          3.0           1.4          0.2  setosa\n",
      "2           4.7          3.2           1.3          0.2  setosa\n",
      "3           4.6          3.1           1.5          0.2  setosa\n",
      "4           5.0          3.6           1.4          0.2  setosa\n"
     ]
    }
   ],
   "source": [
    "print(iris.head())\n",
    "iris.columns\n",
    "iris.dropna(how= \"all\", inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X= iris.ix[:, :4].values\n",
    "#Y= iris.ix[:, 4].values\n",
    "train, test = train_test_split(iris.values,  test_size=.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 - Build a k-Nearest Neighbors Class\n",
    "\n",
    "The derivation can be [found here on Wikipedia](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm). Here is a useful link that explains how to do a [weighted KNN](http://www.csee.umbc.edu/~tinoosh/cmpe650/slides/K_Nearest_Neighbor_Algorithm.pdf).\n",
    "\n",
    "The general steps are:\n",
    "- Locate the k most similar data instances from a test instance\n",
    "    - This is done by calculating the distance from each instance in the data set to the test instance\n",
    "- Return the predicted class label \n",
    "- Return an accuracy measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from operator import itemgetter\n",
    "\n",
    "class KNNClassifier():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def euclideanDistance(self, instance1, instance2, length):\n",
    "        distance= 0\n",
    "        for x in range(length):            \n",
    "            distance += math.pow((instance1[x]- instance2[x]), 2)\n",
    "            \n",
    "        return math.sqrt(distance)                                   \n",
    "    \n",
    "    def getNeighbors(self, trainingSet, testInstance, k):\n",
    "        distances= []\n",
    "        length = len(testInstance)-1\n",
    "        \n",
    "        for x in range(len(trainingSet)):\n",
    "            dist = self.euclideanDistance(testInstance, trainingSet[x],length)\n",
    "            distances.append((trainingSet[x],dist))\n",
    "        distances.sort(key=itemgetter(1))\n",
    "                       \n",
    "        neighbors = []\n",
    "        for x in range(k):\n",
    "            neighbors.append(distances[x][0])                            \n",
    "                       \n",
    "        return neighbors                       \n",
    "        \n",
    "    def getResponse(self, neighbors):\n",
    "        classVotes ={}                       \n",
    "\n",
    "        for x in range(len(neighbors)):                           \n",
    "            response = neighbors[x][-1]\n",
    "                           \n",
    "            if response in classVotes:\n",
    "                classVotes[response] +=1\n",
    "            else:\n",
    "                classVotes[response] =1                       \n",
    "                       \n",
    "        sortedVotes = sorted(classVotes.items(), key=itemgetter(1), reverse = True)                       \n",
    "        return sortedVotes[0][0]\n",
    "\n",
    "    def get_Accuracy (self, testSet, predictions):\n",
    "        correct=0\n",
    "    \n",
    "        for x in range(len(testSet)):    \n",
    "            if testSet[x][-1] is predictions[x]:\n",
    "                correct +=1\n",
    "         \n",
    "        return correct / float(len(testSet)) *100                    \n",
    "                       \n",
    "    def predict(self, trainingSet, testSet, k=3):\n",
    "        predictions =[]\n",
    "        \n",
    "        for x in range(len(testSet)):\n",
    "            neighbors= self.getNeighbors(trainingSet, testSet[x],k)\n",
    "            result = self.getResponse(neighbors)\n",
    "            predictions.append(result)                                         \n",
    "            print(\"> Predicted=\"+repr(result)+  \", actual=\"+repr(testSet[x][-1]))                                         \n",
    "        accuracy= self.get_Accuracy(testSet, predictions)                \n",
    "        print(\"Accuracy \" + repr(accuracy) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 - Try it out on the Iris Data Set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "knn= KNNClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Predicted='virginica', actual='virginica'\n",
      "> Predicted='virginica', actual='virginica'\n",
      "> Predicted='versicolor', actual='versicolor'\n",
      "> Predicted='setosa', actual='setosa'\n",
      "> Predicted='setosa', actual='setosa'\n",
      "> Predicted='setosa', actual='setosa'\n",
      "> Predicted='versicolor', actual='versicolor'\n",
      "> Predicted='virginica', actual='virginica'\n",
      "> Predicted='virginica', actual='virginica'\n",
      "> Predicted='versicolor', actual='versicolor'\n",
      "> Predicted='versicolor', actual='versicolor'\n",
      "> Predicted='versicolor', actual='versicolor'\n",
      "> Predicted='virginica', actual='virginica'\n",
      "> Predicted='versicolor', actual='versicolor'\n",
      "> Predicted='virginica', actual='virginica'\n",
      "> Predicted='virginica', actual='virginica'\n",
      "> Predicted='virginica', actual='virginica'\n",
      "> Predicted='versicolor', actual='versicolor'\n",
      "> Predicted='versicolor', actual='versicolor'\n",
      "> Predicted='virginica', actual='virginica'\n",
      "> Predicted='versicolor', actual='versicolor'\n",
      "> Predicted='virginica', actual='virginica'\n",
      "> Predicted='setosa', actual='setosa'\n",
      "> Predicted='setosa', actual='setosa'\n",
      "> Predicted='versicolor', actual='versicolor'\n",
      "> Predicted='setosa', actual='setosa'\n",
      "> Predicted='versicolor', actual='versicolor'\n",
      "> Predicted='virginica', actual='virginica'\n",
      "> Predicted='virginica', actual='virginica'\n",
      "> Predicted='virginica', actual='virginica'\n",
      "> Predicted='versicolor', actual='virginica'\n",
      "> Predicted='versicolor', actual='versicolor'\n",
      "> Predicted='versicolor', actual='versicolor'\n",
      "> Predicted='versicolor', actual='versicolor'\n",
      "> Predicted='virginica', actual='virginica'\n",
      "> Predicted='setosa', actual='setosa'\n",
      "> Predicted='virginica', actual='virginica'\n",
      "> Predicted='virginica', actual='virginica'\n",
      "> Predicted='versicolor', actual='versicolor'\n",
      "> Predicted='virginica', actual='virginica'\n",
      "> Predicted='setosa', actual='setosa'\n",
      "> Predicted='setosa', actual='setosa'\n",
      "> Predicted='versicolor', actual='versicolor'\n",
      "> Predicted='virginica', actual='virginica'\n",
      "> Predicted='setosa', actual='setosa'\n",
      "> Predicted='setosa', actual='setosa'\n",
      "> Predicted='virginica', actual='virginica'\n",
      "> Predicted='virginica', actual='virginica'\n",
      "> Predicted='versicolor', actual='virginica'\n",
      "> Predicted='setosa', actual='setosa'\n",
      "> Predicted='versicolor', actual='versicolor'\n",
      "> Predicted='setosa', actual='setosa'\n",
      "> Predicted='versicolor', actual='virginica'\n",
      "> Predicted='virginica', actual='virginica'\n",
      "> Predicted='setosa', actual='setosa'\n",
      "> Predicted='setosa', actual='setosa'\n",
      "> Predicted='setosa', actual='setosa'\n",
      "> Predicted='virginica', actual='virginica'\n",
      "> Predicted='versicolor', actual='versicolor'\n",
      "> Predicted='versicolor', actual='versicolor'\n",
      "Accuracy 95.0%\n"
     ]
    }
   ],
   "source": [
    "knn.predict(train, test, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4 - Check via scikit-learn. Plot the decision regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "X_train= train[:,:4]\n",
    "Y_train= train[:,4]\n",
    "X_test = test[:,:4]\n",
    "\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=1)\n",
    "pred = knn.fit(X_train, Y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16  0  0]\n",
      " [ 0 19  2]\n",
      " [ 0  0 23]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     setosa      1.000     1.000     1.000        16\n",
      " versicolor      0.905     1.000     0.950        19\n",
      "  virginica      1.000     0.920     0.958        25\n",
      "\n",
      "avg / total      0.970     0.967     0.967        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Wow, this works pretty well :)\n",
    "Y_test= test[:,4]\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "print(confusion_matrix(Y_test, pred).T)\n",
    "print(classification_report(Y_test, pred, digits=3))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
